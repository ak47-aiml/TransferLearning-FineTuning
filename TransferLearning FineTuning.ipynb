{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "62d85e48",
   "metadata": {},
   "source": [
    "# Transfer Learning - Fine Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c321f605",
   "metadata": {},
   "source": [
    "<font color='steelblue'>\n",
    "\n",
    "<font size = 4>\n",
    "    \n",
    "Use *`pre-defined`* model with the help of *`Keras.Application`* module. Introduce an example of using *`Keras Functional API`* \n",
    "</font>\n",
    "\n",
    "</font>\n",
    "\n",
    "<font size = 3>\n",
    "    \n",
    "Use the same `EfficientNetB0` model, the allows to classify images, however here replace the input layer and add our own input layer for the images we have<br>\n",
    "    \n",
    "**Following is included here:<br>**\n",
    "    \n",
    "- `Load & Prepare` training and test images<br>\n",
    "- Use `Functional API` to `build layers` for the model\n",
    "- `Train & Evaluate` model\n",
    "- `Explore` model performance\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e64c8265",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a22325f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define location of data\n",
    "dpath = \"../datasets/FoodClasses/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd3d74f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list the directories in dataset\n",
    "for dirpath, dirnames, filenames in os.walk(dpath):\n",
    "    print(f\"{len(dirnames)} directores and {len(filenames)} images in '{dirpath}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad5f639f",
   "metadata": {},
   "source": [
    "<font color = 'slategrey'>\n",
    "<font size = 4>\n",
    "    <b>Note:</b><br><br>\n",
    "- There are more images in test directories then in train directories<br>\n",
    "- Key to showing that transfer learning can perform with less training images<br>\n",
    "- Train on less data<br>\n",
    "</font>\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa00d5da",
   "metadata": {},
   "source": [
    "\n",
    "## Loading and Preparing data<br>\n",
    "\n",
    "<font size = \"3\">\n",
    "    \n",
    "- Load images from the appropriate directories using `image_dataset_from_directory`<br>\n",
    "- It works in the same way as the `flow_from_directory` method<br>\n",
    "- Benefit of this method is that we have a `tf.data.Dataset` object rather than a generator object\n",
    "- `tf.data.Dataset` is a much more efficient API than the `ImageDataGenerator` API\n",
    "    \n",
    "[`tf.data.Dataset`](https://www.tensorflow.org/api_docs/python/tf/data/Dataset)\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da161e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb5332bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SHAPE = (224, 224)\n",
    "BATCH_SIZE = 32\n",
    "IMAGE_SHAPE_COLOR = (224, 224, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ab1bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDir = dpath + \"train\"\n",
    "testDir = dpath + \"test\"\n",
    "trainDir, testDir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eef86fe6",
   "metadata": {},
   "source": [
    "<font size = 4>\n",
    "\n",
    "\n",
    "Parameters to use from the `image_dataset_from_directory()`:\n",
    "- `directory`    - the file path of the target directory for images\n",
    "- `image_size`   - the target image size that we want in our dataset\n",
    "- `batch_size`   - how many images we want to load at a time, e.g. `default is 32`, load 32 images and their labels\n",
    "\n",
    "[`tf.keras.preprocessing` Documentation](https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image_dataset_from_directory)\n",
    "    \n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3160ff30",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training data\")\n",
    "trainData = tf.keras.preprocessing.image_dataset_from_directory(directory = trainDir,\n",
    "                                                  image_size = IMAGE_SHAPE,\n",
    "                                                  batch_size = BATCH_SIZE,\n",
    "                                                  label_mode = \"categorical\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f7a14f",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainData.class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c05eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainData"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8abe43aa",
   "metadata": {},
   "source": [
    "<font size = 3>\n",
    "    \n",
    "`BatchDataset`:\n",
    "    \n",
    "- `(None, 224,224, 3)` is tensor shape, `None` is batch size, `224` is height & width of image, `3` color\n",
    "- `(None, 10)` is tenor shape of the labels, `None` is batch size, `10` number of labels in dataset\n",
    "- Both tensors and labels are of type `tf.float32`\n",
    "    \n",
    "`Batch Size` is `None`, it is like a placeholder that will be filled in when the `image_dataset_from_directory()` is executed\n",
    "    \n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab1dfa4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# example of batch data (taking one batch - size is 32)\n",
    "for images, labels in trainData.take(1):\n",
    "    print(labels, images)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a08c355b",
   "metadata": {},
   "source": [
    "Label above is `one hot encoded` `[0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]`is `hamburger`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66f5b6a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Test data\")\n",
    "testData = tf.keras.preprocessing.image_dataset_from_directory(directory = testDir,\n",
    "                                                               image_size = IMAGE_SHAPE,\n",
    "                                                               batch_size = BATCH_SIZE,\n",
    "                                                               label_mode = \"categorical\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6fbd880",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot the validation and training data separately\n",
    "def plot_loss_curves(history):\n",
    "  \"\"\"\n",
    "  Returns separate loss curves for training and validation metrics.\n",
    "  \"\"\" \n",
    "  loss = history.history['loss']\n",
    "  val_loss = history.history['val_loss']\n",
    "\n",
    "  accuracy = history.history['accuracy']\n",
    "  val_accuracy = history.history['val_accuracy']\n",
    "\n",
    "  epochs = range(len(history.history['loss']))\n",
    "\n",
    "  # Plot loss\n",
    "  plt.plot(epochs, loss, label='training_loss')\n",
    "  plt.plot(epochs, val_loss, label='val_loss')\n",
    "  plt.title('Loss')\n",
    "  plt.xlabel('Epochs')\n",
    "  plt.legend()\n",
    "\n",
    "  # Plot accuracy\n",
    "  plt.figure()\n",
    "  plt.plot(epochs, accuracy, label='training_accuracy')\n",
    "  plt.plot(epochs, val_accuracy, label='val_accuracy')\n",
    "  plt.title('Accuracy')\n",
    "  plt.xlabel('Epochs')\n",
    "  plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e2dabf4",
   "metadata": {},
   "source": [
    "## Transfer Learning - Fine Tuning <br>\n",
    "\n",
    "<font size = 3>\n",
    "\n",
    "- Take the underlying `patterns (weights)` from the pre-defined model and `fine tune` to our dataset\n",
    "- Usually this means training some, many or all the layers of the pre-defined model\n",
    "- Useful when the dataset has `large number of classes` and data is slightly different from the data that the pre-defined model was trained on\n",
    "- An example would be that we want to define our own input shape for the data (`unfreeze` that layer)\n",
    "    \n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45d1cf96",
   "metadata": {},
   "source": [
    "## Transfer Learning use Keras Functional API<br>\n",
    "\n",
    "<font size = 3>\n",
    "    \n",
    "- To use our `predefined model`, use [`tf.keras.applications`](https://www.tensorflow.org/api_docs/python/tf/keras/applications)\n",
    "- This applications module is already set up for using [`Keras Functional API`](https://keras.io/guides/functional_api/)\n",
    "    \n",
    "Perform following steps:\n",
    "1. Instantiate a pre-trained base model object [`EfficientNetB0`](https://www.tensorflow.org/api_docs/python/tf/keras/applications/EfficientNetB0) from `tf.keras.applications`, setting the `include_top` parameter to `False` (we do this because we're going to create our own top, which are the output layers for the model).\n",
    "2. Set base model to `un-trainable`, so that all the weights in the predefined model are frozen\n",
    "3. Create the `input layer` for the model (set the `shape to our image size`)\n",
    "4. Pass the `input layer` to the `base model` created in the steps above\n",
    "5. Pool the outputs of the base model into a shape compatible with the output activation layer (turn base model output tensors into same shape as label tensors). This can be done using [`tf.keras.layers.GlobalAveragePooling2D()`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/GlobalAveragePooling2D) or [`tf.keras.layers.GlobalMaxPooling2D()`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/GlobalMaxPool2D?hl=en) though the former is more common in practice.\n",
    "6. Create `output activation layer` with appropriate `number of neurons` and `tf.layers.Dense()`\n",
    "7. Combine the inputs and the outputs into a model using [`tf.Keras.Model`](https://www.tensorflow.org/api_docs/python/tf/keras/Model)\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "636ed6ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import tensorflow as tf\n",
    "#import tensorflow_hub as hub\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3cc921b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Create base model\n",
    "baseModel = tf.keras.applications.EfficientNetB0(include_top = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7116f820",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Freeze the base model\n",
    "baseModel.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb363bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. inputs into the base model\n",
    "inputs = tf.keras.layers.Input(shape = IMAGE_SHAPE_COLOR, name = \"InputLayer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f88bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Pass input layer to base model\n",
    "x = baseModel(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "066d38f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d225839c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Average pool the outputs of the base model\n",
    "x = tf.keras.layers.GlobalAveragePooling2D(name = \"GlobalAvgPooling\") (x)\n",
    "print(f\"After average pooling shape is: {x.shape}\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4111908b",
   "metadata": {},
   "source": [
    "x = tf.keras.layers.Dense(16, activation = 'relu', name = 'Dense')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b3bfe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Create output activation layer\n",
    "outputs = tf.keras.layers.Dense(len(trainData.class_names), \n",
    "                                activation = \"softmax\",\n",
    "                                name = \"OutputLayer\") (x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "419b72e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Combine the inputs and outputs into a Model\n",
    "effNetModel = tf.keras.Model(inputs, outputs, name = \"FineTuning\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "454b47f3",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "757ca704",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile model\n",
    "effNetModel.compile(loss = \"categorical_crossentropy\",\n",
    "                   optimizer = tf.keras.optimizers.Adam(),\n",
    "                   metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde173f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# train model (takes about 25+ minutes)\n",
    "\n",
    "tf.random.set_seed(2345)\n",
    "effNetHistory = effNetModel.fit(trainData,\n",
    "                               epochs = 5,\n",
    "                               steps_per_epoch = len(trainData),\n",
    "                               validation_data = testData,\n",
    "                               validation_steps = len(testData),\n",
    "                               verbose = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e972672e",
   "metadata": {},
   "source": [
    "## Model Perfomance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "614a8ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss_curves(effNetHistory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac8ad97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check out the layers in the base model\n",
    "for layerNum, layer in enumerate(baseModel.layers):\n",
    "    print(layerNum, layer.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de44415c",
   "metadata": {},
   "source": [
    "<font size = 3>\n",
    "\n",
    "- A lot of layers here, if we were to hand code this will take a fairly long time\n",
    "- These are the benefits of transfer learning\n",
    "    \n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "721a8e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary of base model\n",
    "baseModel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a52bf668",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model summary\n",
    "effNetModel.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf254f1",
   "metadata": {},
   "source": [
    "<font size = 3>\n",
    "  \n",
    "- The `InputLayer` has a shape of `(None, 224, 224, 3)`,  the `None` is a placeholder for the `batch size`\n",
    "- The EfficientNetB0 has 236 layers (check the type it is `Functional`)\n",
    "- In the output layer `(None, 10)`, 10 is the number of classes and `None` is batch size\n",
    "- There are more that `4M parameters` of which only `12,810 are trainable`\n",
    "- *(`1280 * 10`) neurons in output layer, + `10` biases for each neuron = **12,810**)*\n",
    "    \n",
    "    \n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59336979",
   "metadata": {},
   "source": [
    "### GlobalAveragePooling2D<br>\n",
    "\n",
    "<font size = 3>\n",
    "\n",
    "- The 4D tensors coming from the `EfficientNetB0` layer need to be converted into 2D tensors since our output layer is 10 classes\n",
    "- Apply `tf.keras.GlobalAveragePooling2D()` to average inner axes in the tensors\n",
    "- Here is an example:    \n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a1ae66b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define same dimensions as the output of the EfficientNetB0\n",
    "inputShape = (1, 4, 4, 3)\n",
    "\n",
    "# create a random tensor\n",
    "tf.random.set_seed(2345)          # make repeatable\n",
    "\n",
    "inTensor = tf.random.normal(inputShape)\n",
    "print(f\"Random input tensor:\\n {inTensor}\")\n",
    "print(f\"Number of dimensions: {inTensor.ndim}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54353f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pass the tensor through global average pooling 2D layer\n",
    "gblAvgPoolTensor = tf.keras.layers.GlobalAveragePooling2D() (inTensor)\n",
    "print(f\"Tensor after Global Average Pooling:\\n {gblAvgPoolTensor}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "948c40fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# explore input shape of tensor\n",
    "inTensor.shape, inTensor.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a08ac3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# explore output shape of tensor\n",
    "gblAvgPoolTensor.shape, gblAvgPoolTensor.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c0483aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# can also be done by using reduce_mean\n",
    "# create average on middle axes\n",
    "tf.reduce_mean(inTensor, axis = [1, 2])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
